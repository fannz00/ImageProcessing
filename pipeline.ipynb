{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmenter import run_segmenter\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "from pandas.errors import EmptyDataError\n",
    "import numpy as np\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "folder_path = '/home/fanny/segmentation_output/Data' \n",
    "csv_files = []\n",
    "\n",
    "#create one list of csv files\n",
    "for file in os.listdir(folder_path):\n",
    "    if file.endswith('.csv'):\n",
    "        csv_files.append(os.path.join(folder_path, file))\n",
    "\n",
    "#print(csv_files)\n",
    "\n",
    "# select the crops only\n",
    "def select_crops(data_file):\n",
    "    list_crops = []\n",
    "    with open(data_file, \"r\") as file:\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            if len(row) > 12:\n",
    "                list_crops.append(row)\n",
    "    return list_crops\n",
    "\n",
    "\n",
    "# create list of data frames\n",
    "df_list = []\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    selected_rows = select_crops(csv_file)\n",
    "    if selected_rows: # if there are any rows\n",
    "        df = pd.DataFrame(selected_rows)\n",
    "        df_list.append(df)\n",
    "    \n",
    "\n",
    "# Combine all DataFrames into one\n",
    "if df_list: # Check if df_list has any DataFrames to concatenate\n",
    "    combined_df = pd.concat(df_list, ignore_index=True)\n",
    "    print(combined_df.head())\n",
    "\n",
    "    # Save the combined DataFrame to a CSV file\n",
    "    combined_df.to_csv(\"/home/fanny/output_dataframes/combined_data.csv\", index=False, header=True)\n",
    "else:\n",
    "    print(\"no valid data found\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '/home/fanny/segmentation_output/Data' \n",
    "csv_files = []\n",
    "\n",
    "for file in os.listdir(folder_path):\n",
    "    if file.endswith('.csv'):\n",
    "        csv_files.append(os.path.join(folder_path, file))\n",
    "\n",
    "\n",
    "df = []\n",
    "for csv_file in csv_files:\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df_list.append(df)\n",
    "\n",
    "df_combined = pd.concat(map(pd.read_csv, csv_files))\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:00<00:00, 268.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 files were empty and were dropped; Number of uniue images: 51\n"
     ]
    }
   ],
   "source": [
    "def gen_crop_df(path:str, small:bool, size_filter:int = 0):\n",
    "    \"\"\"\n",
    "    A function to generate a DataFrame from a directory of CSV files, with options to filter out small objects.\n",
    "    Parameters:\n",
    "    path (str): The path to the directory containing the CSV files.\n",
    "    small (bool): A flag indicating whether to filter out small objects.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: The concatenated and processed DataFrame with additional columns for analysis.\n",
    "    \"\"\"\n",
    "\n",
    "    def area_to_esd(area: float) -> float:\n",
    "        pixel_size = 13.5*2 #in µm/pixel @ 2560x2560 \n",
    "        return 2 * np.sqrt(area * pixel_size**2 / np.pi)\n",
    "\n",
    "    # Function to concatenate directory and filename\n",
    "    def join_strings(dir, filename):\n",
    "        return os.path.join(dir, filename)\n",
    "\n",
    "    directory = os.path.dirname(path)\n",
    "    directory = os.path.join(directory,'Data')\n",
    "\n",
    "    files = [os.path.join(path, file) for file in sorted(os.listdir(path)) if file.endswith(\".csv\")]\n",
    "    dataframes = []\n",
    "    empty_file_counter = 0\n",
    "    id = 1\n",
    "    for file in tqdm(files):\n",
    "        try:\n",
    "            df = pd.read_csv(file, delimiter=\",\", header=None, index_col=None)\n",
    "            if len(df.columns) == 44:\n",
    "                df.insert(0,'',id)            \n",
    "                dataframes.append(df)\n",
    "                id+=1\n",
    "            else:\n",
    "                continue\n",
    "        except EmptyDataError:\n",
    "            empty_file_counter += 1\n",
    "            print(f\"File {file} is empty\")\n",
    "\n",
    "    df = pd.concat(dataframes, ignore_index=True)\n",
    "    headers = [\"img_id\",\"index\", \"filename\", \"mean_raw\", \"std_raw\", \"mean\", \"std\", \"area\", \"x\", \"y\", \"w\", \"h\", \n",
    "               \"saved\", \"object_bound_box_w\", \"object_bound_box_h\", \"bound_box_x\", \"bound_box_y\", \"object_circularity\", \"object_area_exc\", \n",
    "               \"object_area_rprops\", \"object_%area\", \"object_major_axis_len\", \"object_minor_axis_len\", \"object_centroid_y\", \"object_centroid_x\", \n",
    "               \"object_convex_area\", \"object_min_intensity\", \"object_max_intensity\", \"object_mean_intensity\", \"object_int_density\", \"object_perimeter\", \n",
    "               \"object_elongation\", \"object_range\", \"object_perim_area_excl\", \"object_perim_major\", \"object_circularity_area_excl\", \"object_angle\", \n",
    "               \"object_boundbox_area\", \"object_eccentricity\", \"object_equivalent_diameter\", \"object_euler_nr\", \"object_extent\", \n",
    "               \"object_local_centroid_col\", \"object_local_centroid_row\", \"object_solidity\"\n",
    "]\n",
    "    df.columns = headers\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df.drop(\"index\", axis=1, inplace=True)\n",
    "\n",
    "    if not small:\n",
    "        df = df[df[\"saved\"] == 1]\n",
    "    df_unique = df.drop_duplicates(subset=['img_id'])\n",
    "    \n",
    "    #df.drop(\"saved\", axis=1, inplace=True)\n",
    "\n",
    "    # Split the 'filename' column\n",
    "    split_df = df['filename'].str.split('_', expand=True)\n",
    "    if small:# bug fix for segmenter where small objects are saved with _mask.png extension instead of .png: needs to be fixed if segmenter is fixed\n",
    "        headers = [\"date\", \"time\", \"pressure\", \"temperature\", \"index\", \"mask_ext\"]\n",
    "        split_df.columns = headers\n",
    "        split_df.drop(\"mask_ext\", axis=1, inplace=True)\n",
    "    else:\n",
    "        headers = [\"date-time\", \"pressure\", \"temperature\", \"index\", 'drop']\n",
    "        split_df.columns = headers\n",
    "        split_df.drop(\"drop\", axis=1, inplace=True)\n",
    "    \n",
    "    # split date-time\n",
    "    split_df[['date', 'time']] = split_df['date-time'].str.split('-', expand=True)\n",
    "    split_df.drop(columns=['date-time'], inplace=True)\n",
    "\n",
    "    split_df['pressure'] = split_df['pressure'].str.replace('bar', '', regex=False).astype(float)\n",
    "    split_df['temperature'] = split_df['temperature'].str.replace('C', '', regex=False).astype(float)\n",
    "    split_df['index'] = split_df['index'].str.replace('.png', '', regex=False).astype(int)\n",
    "\n",
    "    # Concatenate the new columns with the original DataFrame\n",
    "    df = pd.concat([split_df, df], axis=1)\n",
    "\n",
    "    # Extend the original 'filename' column\n",
    "    df['full_path'] = df.apply(lambda x: join_strings(directory, x['filename']), axis=1)\n",
    "    #df = df.drop('filename', axis=1)\n",
    "\n",
    "    df['esd'] = df['area'].apply(area_to_esd).round(2)\n",
    "    df['pressure'] = (df['pressure']-1)*10\n",
    "    df.rename(columns={'pressure': 'pressure [dbar]'}, inplace=True)\n",
    "\n",
    "    # Sort the DataFrame by the 'date-time' column\n",
    "    df = df.sort_values(by=['date', 'time','index'], ascending=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    #filter the df for objects where 1 dimension is larger than ca. 1mm\n",
    "    df = df[(df['w'] > size_filter) | (df['h'] > size_filter)]\n",
    "    df_unique = df.drop_duplicates(subset=['img_id'])\n",
    "    print(f'{empty_file_counter} files were empty and were dropped; Number of uniue images: {len(df_unique)}')\n",
    "\n",
    "    return df\n",
    "\n",
    "file_path = '/home/fanny/segmentation_output/Data'\n",
    "segmentation_df = gen_crop_df(file_path, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>top1</th>\n",
       "      <th>top2</th>\n",
       "      <th>top3</th>\n",
       "      <th>top4</th>\n",
       "      <th>top5</th>\n",
       "      <th>prob1</th>\n",
       "      <th>prob2</th>\n",
       "      <th>prob3</th>\n",
       "      <th>prob4</th>\n",
       "      <th>prob5</th>\n",
       "      <th>object_annotation_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/fanny/segmentation_output/Deconv_crops/2...</td>\n",
       "      <td>Acantharia</td>\n",
       "      <td>Unknowns</td>\n",
       "      <td>Protista</td>\n",
       "      <td>Protista</td>\n",
       "      <td>Trichodesmium</td>\n",
       "      <td>0.436174</td>\n",
       "      <td>0.127273</td>\n",
       "      <td>0.116326</td>\n",
       "      <td>0.076356</td>\n",
       "      <td>0.045707</td>\n",
       "      <td>predicted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/fanny/segmentation_output/Deconv_crops/2...</td>\n",
       "      <td>Protista</td>\n",
       "      <td>Unknowns</td>\n",
       "      <td>Protista</td>\n",
       "      <td>Acantharia</td>\n",
       "      <td>Unknowns</td>\n",
       "      <td>0.664016</td>\n",
       "      <td>0.146700</td>\n",
       "      <td>0.054679</td>\n",
       "      <td>0.027206</td>\n",
       "      <td>0.016088</td>\n",
       "      <td>predicted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/fanny/segmentation_output/Deconv_crops/2...</td>\n",
       "      <td>Detritus</td>\n",
       "      <td>Detritus</td>\n",
       "      <td>Unknowns</td>\n",
       "      <td>Fecal pellets</td>\n",
       "      <td>Detritus</td>\n",
       "      <td>0.494211</td>\n",
       "      <td>0.430913</td>\n",
       "      <td>0.021329</td>\n",
       "      <td>0.010284</td>\n",
       "      <td>0.008775</td>\n",
       "      <td>predicted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/fanny/segmentation_output/Deconv_crops/2...</td>\n",
       "      <td>Protista</td>\n",
       "      <td>Protista</td>\n",
       "      <td>Detritus</td>\n",
       "      <td>Detritus</td>\n",
       "      <td>Trichodesmium</td>\n",
       "      <td>0.311248</td>\n",
       "      <td>0.190141</td>\n",
       "      <td>0.181070</td>\n",
       "      <td>0.077617</td>\n",
       "      <td>0.067613</td>\n",
       "      <td>predicted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/fanny/segmentation_output/Deconv_crops/2...</td>\n",
       "      <td>Trichodesmium</td>\n",
       "      <td>Detritus</td>\n",
       "      <td>Unknowns</td>\n",
       "      <td>Fecal pellets</td>\n",
       "      <td>Chaetognatha</td>\n",
       "      <td>0.845670</td>\n",
       "      <td>0.071942</td>\n",
       "      <td>0.058176</td>\n",
       "      <td>0.009616</td>\n",
       "      <td>0.001538</td>\n",
       "      <td>predicted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>/home/fanny/segmentation_output/Deconv_crops/2...</td>\n",
       "      <td>Unknowns</td>\n",
       "      <td>Protista</td>\n",
       "      <td>Unknowns</td>\n",
       "      <td>Detritus</td>\n",
       "      <td>Hydromedusae</td>\n",
       "      <td>0.338783</td>\n",
       "      <td>0.323545</td>\n",
       "      <td>0.092405</td>\n",
       "      <td>0.046433</td>\n",
       "      <td>0.043990</td>\n",
       "      <td>predicted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>/home/fanny/segmentation_output/Deconv_crops/2...</td>\n",
       "      <td>Detritus</td>\n",
       "      <td>Unknowns</td>\n",
       "      <td>Trichodesmium</td>\n",
       "      <td>Unknowns</td>\n",
       "      <td>Crustacea</td>\n",
       "      <td>0.471309</td>\n",
       "      <td>0.341310</td>\n",
       "      <td>0.041979</td>\n",
       "      <td>0.023661</td>\n",
       "      <td>0.017594</td>\n",
       "      <td>predicted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>/home/fanny/segmentation_output/Deconv_crops/2...</td>\n",
       "      <td>Unknowns</td>\n",
       "      <td>Detritus</td>\n",
       "      <td>Trichodesmium</td>\n",
       "      <td>Unknowns</td>\n",
       "      <td>Doliolida</td>\n",
       "      <td>0.704372</td>\n",
       "      <td>0.025734</td>\n",
       "      <td>0.023721</td>\n",
       "      <td>0.022455</td>\n",
       "      <td>0.019465</td>\n",
       "      <td>predicted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>/home/fanny/segmentation_output/Deconv_crops/2...</td>\n",
       "      <td>Detritus</td>\n",
       "      <td>Detritus</td>\n",
       "      <td>Unknowns</td>\n",
       "      <td>Detritus</td>\n",
       "      <td>Artefact</td>\n",
       "      <td>0.613329</td>\n",
       "      <td>0.235042</td>\n",
       "      <td>0.048409</td>\n",
       "      <td>0.026416</td>\n",
       "      <td>0.010740</td>\n",
       "      <td>predicted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>/home/fanny/segmentation_output/Deconv_crops/2...</td>\n",
       "      <td>Detritus</td>\n",
       "      <td>Fecal pellets</td>\n",
       "      <td>Detritus</td>\n",
       "      <td>Trichodesmium</td>\n",
       "      <td>Unknowns</td>\n",
       "      <td>0.856335</td>\n",
       "      <td>0.043042</td>\n",
       "      <td>0.041724</td>\n",
       "      <td>0.023043</td>\n",
       "      <td>0.005602</td>\n",
       "      <td>predicted</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1260 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               filename           top1  \\\n",
       "0     /home/fanny/segmentation_output/Deconv_crops/2...     Acantharia   \n",
       "1     /home/fanny/segmentation_output/Deconv_crops/2...       Protista   \n",
       "2     /home/fanny/segmentation_output/Deconv_crops/2...       Detritus   \n",
       "3     /home/fanny/segmentation_output/Deconv_crops/2...       Protista   \n",
       "4     /home/fanny/segmentation_output/Deconv_crops/2...  Trichodesmium   \n",
       "...                                                 ...            ...   \n",
       "1255  /home/fanny/segmentation_output/Deconv_crops/2...       Unknowns   \n",
       "1256  /home/fanny/segmentation_output/Deconv_crops/2...       Detritus   \n",
       "1257  /home/fanny/segmentation_output/Deconv_crops/2...       Unknowns   \n",
       "1258  /home/fanny/segmentation_output/Deconv_crops/2...       Detritus   \n",
       "1259  /home/fanny/segmentation_output/Deconv_crops/2...       Detritus   \n",
       "\n",
       "               top2           top3           top4           top5     prob1  \\\n",
       "0          Unknowns       Protista       Protista  Trichodesmium  0.436174   \n",
       "1          Unknowns       Protista     Acantharia       Unknowns  0.664016   \n",
       "2          Detritus       Unknowns  Fecal pellets       Detritus  0.494211   \n",
       "3          Protista       Detritus       Detritus  Trichodesmium  0.311248   \n",
       "4          Detritus       Unknowns  Fecal pellets   Chaetognatha  0.845670   \n",
       "...             ...            ...            ...            ...       ...   \n",
       "1255       Protista       Unknowns       Detritus   Hydromedusae  0.338783   \n",
       "1256       Unknowns  Trichodesmium       Unknowns      Crustacea  0.471309   \n",
       "1257       Detritus  Trichodesmium       Unknowns      Doliolida  0.704372   \n",
       "1258       Detritus       Unknowns       Detritus       Artefact  0.613329   \n",
       "1259  Fecal pellets       Detritus  Trichodesmium       Unknowns  0.856335   \n",
       "\n",
       "         prob2     prob3     prob4     prob5 object_annotation_status  \n",
       "0     0.127273  0.116326  0.076356  0.045707                predicted  \n",
       "1     0.146700  0.054679  0.027206  0.016088                predicted  \n",
       "2     0.430913  0.021329  0.010284  0.008775                predicted  \n",
       "3     0.190141  0.181070  0.077617  0.067613                predicted  \n",
       "4     0.071942  0.058176  0.009616  0.001538                predicted  \n",
       "...        ...       ...       ...       ...                      ...  \n",
       "1255  0.323545  0.092405  0.046433  0.043990                predicted  \n",
       "1256  0.341310  0.041979  0.023661  0.017594                predicted  \n",
       "1257  0.025734  0.023721  0.022455  0.019465                predicted  \n",
       "1258  0.235042  0.048409  0.026416  0.010740                predicted  \n",
       "1259  0.043042  0.041724  0.023043  0.005602                predicted  \n",
       "\n",
       "[1260 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare prediction data\n",
    "import re\n",
    "\n",
    "prediction_df = pd.read_csv(\"/home/fanny/segmentation_output/ViT_predictions.csv\")\n",
    "polytaxo_classes_df = pd.read_csv('/home/fanny/taxonomic_data/Polytaxo_classes(1).csv', sep=\";\")\n",
    "\n",
    "print(len(polytaxo_classes_df.columns))\n",
    "\n",
    "prediction_df['object_annotation_status'] = 'predicted'\n",
    "\n",
    "mapping_dict = dict(zip(polytaxo_classes_df[\"Dataset Class NamePolyTaxo Description\"], polytaxo_classes_df[\"PolyTaxo Description\"]))\n",
    "columns_to_replace = [\"top1\", \"top2\", \"top3\", \"top4\", \"top5\"]\n",
    "\n",
    "# Define regex pattern to split on space, semicolon, colon, or slash\n",
    "split_pattern = r\"[ ;:/]\"\n",
    "\n",
    "'''\n",
    "#prediction_df[columns_to_replace] = prediction_df[columns_to_replace].replace(mapping_dict)\n",
    "prediction_df[columns_to_replace] = (\n",
    "    prediction_df[columns_to_replace]\n",
    "    .replace(mapping_dict)\n",
    "    .applymap(lambda x: re.split(split_pattern, str(x))[0] if pd.notna(x) else x)\n",
    ")\n",
    "'''\n",
    "\n",
    "'''\n",
    "# Replace values and extract only the first word\n",
    "prediction_df[columns_to_replace] = prediction_df[columns_to_replace].replace(mapping_dict).apply(\n",
    "    lambda col: col.astype(str).apply(lambda x: re.split(split_pattern, x)[0] if pd.notna(x) else x)\n",
    ")\n",
    "\n",
    "prediction_df[columns_to_replace ]\n",
    "for row\n",
    "'''\n",
    "\n",
    "\n",
    "# Replace values, extract first word, and replace underscores with spaces\n",
    "prediction_df[columns_to_replace] = prediction_df[columns_to_replace].replace(mapping_dict).apply(\n",
    "    lambda col: col.astype(str).apply(\n",
    "        lambda x: re.split(split_pattern, x)[0].replace(\"_\", \" \") if pd.notna(x) else x\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets try something else\n",
    "#taxoexport_df = pd.read_csv(\"/home/fanny/taxonomic_data/taxoexport_20250212_140806.tsv\")\n",
    "\n",
    "# Find common categories\n",
    "#common_categories = set(polytaxo_classes_df['Dataset Class NamePolyTaxo Description']).intersection(set(taxoexport_df['display_name']))\n",
    "#print(\"Direct matches found:\", len(common_categories))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4429/308653040.py:56: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[f]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  segm_and_prediction_df.loc[0] = dtype_row\n",
      "/tmp/ipykernel_4429/308653040.py:56: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[f]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  segm_and_prediction_df.loc[0] = dtype_row\n",
      "/tmp/ipykernel_4429/308653040.py:56: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[f]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  segm_and_prediction_df.loc[0] = dtype_row\n",
      "/tmp/ipykernel_4429/308653040.py:56: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[f]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  segm_and_prediction_df.loc[0] = dtype_row\n",
      "/tmp/ipykernel_4429/308653040.py:56: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[f]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  segm_and_prediction_df.loc[0] = dtype_row\n",
      "/tmp/ipykernel_4429/308653040.py:56: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[f]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  segm_and_prediction_df.loc[0] = dtype_row\n",
      "/tmp/ipykernel_4429/308653040.py:56: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[f]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  segm_and_prediction_df.loc[0] = dtype_row\n",
      "/tmp/ipykernel_4429/308653040.py:56: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[f]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  segm_and_prediction_df.loc[0] = dtype_row\n",
      "/tmp/ipykernel_4429/308653040.py:56: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[f]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  segm_and_prediction_df.loc[0] = dtype_row\n",
      "/tmp/ipykernel_4429/308653040.py:56: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[f]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  segm_and_prediction_df.loc[0] = dtype_row\n",
      "/tmp/ipykernel_4429/308653040.py:56: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[f]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  segm_and_prediction_df.loc[0] = dtype_row\n",
      "/tmp/ipykernel_4429/308653040.py:56: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[f]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  segm_and_prediction_df.loc[0] = dtype_row\n",
      "/tmp/ipykernel_4429/308653040.py:56: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[f]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  segm_and_prediction_df.loc[0] = dtype_row\n",
      "/tmp/ipykernel_4429/308653040.py:56: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[f]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  segm_and_prediction_df.loc[0] = dtype_row\n",
      "/tmp/ipykernel_4429/308653040.py:56: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[f]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  segm_and_prediction_df.loc[0] = dtype_row\n",
      "/tmp/ipykernel_4429/308653040.py:56: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[f]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  segm_and_prediction_df.loc[0] = dtype_row\n",
      "/tmp/ipykernel_4429/308653040.py:56: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[f]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  segm_and_prediction_df.loc[0] = dtype_row\n",
      "/tmp/ipykernel_4429/308653040.py:56: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[f]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  segm_and_prediction_df.loc[0] = dtype_row\n",
      "/tmp/ipykernel_4429/308653040.py:56: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[f]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  segm_and_prediction_df.loc[0] = dtype_row\n",
      "/tmp/ipykernel_4429/308653040.py:56: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[f]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  segm_and_prediction_df.loc[0] = dtype_row\n",
      "/tmp/ipykernel_4429/308653040.py:56: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[f]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  segm_and_prediction_df.loc[0] = dtype_row\n",
      "/tmp/ipykernel_4429/308653040.py:56: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[f]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  segm_and_prediction_df.loc[0] = dtype_row\n",
      "/tmp/ipykernel_4429/308653040.py:56: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[f]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  segm_and_prediction_df.loc[0] = dtype_row\n",
      "/tmp/ipykernel_4429/308653040.py:56: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[f]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  segm_and_prediction_df.loc[0] = dtype_row\n",
      "/tmp/ipykernel_4429/308653040.py:56: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[f]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  segm_and_prediction_df.loc[0] = dtype_row\n",
      "/tmp/ipykernel_4429/308653040.py:56: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[f]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  segm_and_prediction_df.loc[0] = dtype_row\n",
      "/tmp/ipykernel_4429/308653040.py:56: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[f]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  segm_and_prediction_df.loc[0] = dtype_row\n",
      "/tmp/ipykernel_4429/308653040.py:56: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[f]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  segm_and_prediction_df.loc[0] = dtype_row\n",
      "/tmp/ipykernel_4429/308653040.py:56: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[f]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  segm_and_prediction_df.loc[0] = dtype_row\n",
      "/tmp/ipykernel_4429/308653040.py:56: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[f]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  segm_and_prediction_df.loc[0] = dtype_row\n",
      "/tmp/ipykernel_4429/308653040.py:56: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[f]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  segm_and_prediction_df.loc[0] = dtype_row\n",
      "/tmp/ipykernel_4429/308653040.py:56: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[f]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  segm_and_prediction_df.loc[0] = dtype_row\n",
      "/tmp/ipykernel_4429/308653040.py:56: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[f]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  segm_and_prediction_df.loc[0] = dtype_row\n",
      "/tmp/ipykernel_4429/308653040.py:56: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[f]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  segm_and_prediction_df.loc[0] = dtype_row\n",
      "/tmp/ipykernel_4429/308653040.py:56: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[f]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  segm_and_prediction_df.loc[0] = dtype_row\n",
      "/tmp/ipykernel_4429/308653040.py:56: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[f]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  segm_and_prediction_df.loc[0] = dtype_row\n",
      "/tmp/ipykernel_4429/308653040.py:56: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[f]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  segm_and_prediction_df.loc[0] = dtype_row\n",
      "/tmp/ipykernel_4429/308653040.py:56: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[f]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  segm_and_prediction_df.loc[0] = dtype_row\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deconv_crops folder has been zipped to /home/fanny/segmentation_output/EcoTaxa/ecotaxa_upload.zip\n"
     ]
    }
   ],
   "source": [
    "# combine segmentation data frame with prediction data frame\n",
    "# Sort both DataFrames by 'filename'\n",
    "segmentation_df_sorted = segmentation_df.sort_values(by='filename').reset_index(drop=True)\n",
    "prediction_df_sorted = prediction_df.sort_values(by='filename').reset_index(drop=True)\n",
    "\n",
    "# concatenate data frames\n",
    "segm_and_prediction_df = pd.concat([segmentation_df_sorted, prediction_df_sorted], axis=1)\n",
    "segm_and_prediction_df = segm_and_prediction_df.loc[:, ~segm_and_prediction_df.columns.duplicated(keep='first')]\n",
    "\n",
    "# add object id\n",
    "segm_and_prediction_df['object_id'] = segm_and_prediction_df['img_id'].astype(str) + '_' + segm_and_prediction_df['index'].astype(str)\n",
    "\n",
    "# Create list of file paths from the 'file_paths' column\n",
    "#filepaths = segm_and_prediction_df['file_paths'].tolist()\n",
    "\n",
    "# delete some columns\n",
    "columns_to_delete = ['temperature', 'mean_raw', 'std_raw', 'mean', 'std', 'x', 'y', 'w', 'h', 'saved', 'bound_box_x', 'bound_box_y', 'full_path', 'img_id', 'index']\n",
    "segm_and_prediction_df.drop(columns_to_delete, axis=1, inplace=True)\n",
    "\n",
    "# adjust header names\n",
    "segm_and_prediction_df = segm_and_prediction_df.rename(columns={\n",
    "    'pressure [dbar]' : 'object_pressure',\n",
    "    'date': 'object_date',\n",
    "    'time' : 'object_time',\n",
    "    'filename' : 'img_file_name',\n",
    "    'area' : 'object_area',\n",
    "    'esd' : 'object_esd',\n",
    "    'top1' : 'object_annotation_category',\n",
    "    'top2' : 'object_annotation_category_2',\n",
    "    'top3' : 'object_annotation_category_3',\n",
    "    'top4' : 'object_annotation_category_4',\n",
    "    'top5' : 'object_annotation_category_5',\n",
    "    'prob1' : 'object_prob_1',\n",
    "    'prob2' : 'object_prob_2',\n",
    "    'prob3': 'object_prob_3',\n",
    "    'prob4' : 'object_prob_4',\n",
    "    'prob5' : 'object_prob_5'    \n",
    "})\n",
    "#print(segm_and_prediction_df.columns)\n",
    "\n",
    "\n",
    "# function to determine the data type of each column\n",
    "def determine_dtype(dtype):\n",
    "    if pd.api.types.is_numeric_dtype(dtype):\n",
    "        return '[f]' \n",
    "    elif pd.api.types.is_string_dtype(dtype):\n",
    "        return '[t]'\n",
    "    else:\n",
    "        return 'other'\n",
    "\n",
    "dtype_row = []\n",
    "for col in segm_and_prediction_df.columns:\n",
    "    dtype_row.append(determine_dtype(segm_and_prediction_df[col].dtype))\n",
    "\n",
    "# insert row\n",
    "segm_and_prediction_df.loc[0] = dtype_row\n",
    "\n",
    "# reset index to maintain order\n",
    "segm_and_prediction_df = segm_and_prediction_df.sort_index().reset_index(drop=True)\n",
    "eco_taxa_folder = \"/home/fanny/segmentation_output/EcoTaxa\"\n",
    "os.makedirs(eco_taxa_folder, exist_ok=True)\n",
    "\n",
    "# save everything as tsv file\n",
    "segm_and_prediction_df.to_csv('/home/fanny/segmentation_output/Deconv_crops/ecotaxa_metadata.tsv', sep=\"\\t\", index=False)\n",
    "\n",
    "deconv_crops_folder = '/home/fanny/segmentation_output/Deconv_crops'\n",
    "\n",
    "# Define the output zip file path\n",
    "zip_path = \"/home/fanny/segmentation_output/EcoTaxa/ecotaxa_upload.zip\"\n",
    "\n",
    "# Create a zip archive of the entire Deconv_crops folder (including images and metadata file)\n",
    "shutil.make_archive(zip_path.replace(\".zip\", \"\"), 'zip', deconv_crops_folder)\n",
    "\n",
    "print(f\"Deconv_crops folder has been zipped to {zip_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classlist = ['acantharia_protist',\n",
    "'acantharia_protist_big_center',\n",
    "'acantharia_protist_halo',\n",
    "'amphipods',\n",
    "'appendicularian_fritillaridae',\n",
    "'appendicularian_s_shape',\n",
    "'appendicularian_slight_curve',\n",
    "'appendicularian_straight',\n",
    "'artifacts',\n",
    "'artifacts_edge',\n",
    "'chaetognath_non_sagitta',\n",
    "'chaetognath_other',\n",
    "'chaetognath_sagitta',\n",
    "'chordate_type1',\n",
    "'copepod_calanoid',\n",
    "'copepod_calanoid_eggs',\n",
    "'copepod_calanoid_eucalanus',\n",
    "'copepod_calanoid_flatheads',\n",
    "'copepod_calanoid_frillyAntennae',\n",
    "'copepod_calanoid_large',\n",
    "'copepod_calanoid_large_side_antennatucked',\n",
    "'copepod_calanoid_octomoms',\n",
    "'copepod_calanoid_small_longantennae',\n",
    "'copepod_cyclopoid_copilia',\n",
    "'copepod_cyclopoid_oithona',\n",
    "'copepod_cyclopoid_oithona_eggs',\n",
    "'copepod_other',\n",
    "'crustacean_other',\n",
    "'ctenophore_cestid',\n",
    "'ctenophore_cydippid_no_tentacles',\n",
    "'ctenophore_cydippid_tentacles',\n",
    "'ctenophore_lobate',\n",
    "'decapods',\n",
    "'detritus_blob',\n",
    "'detritus_filamentous',\n",
    "'detritus_other',\n",
    "'diatom_chain_string',\n",
    "'diatom_chain_tube',\n",
    "'echinoderm_larva_pluteus_brittlestar',\n",
    "'echinoderm_larva_pluteus_early',\n",
    "'echinoderm_larva_pluteus_typeC',\n",
    "'echinoderm_larva_pluteus_urchin',\n",
    "'echinoderm_larva_seastar_bipinnaria',\n",
    "'echinoderm_larva_seastar_brachiolaria',\n",
    "'echinoderm_seacucumber_auricularia_larva',\n",
    "'echinopluteus',\n",
    "'ephyra',\n",
    "'euphausiids',\n",
    "'euphausiids_young',\n",
    "'fecal_pellet',\n",
    "'fish_larvae_deep_body',\n",
    "'fish_larvae_leptocephali',\n",
    "'fish_larvae_medium_body',\n",
    "'fish_larvae_myctophids',\n",
    "'fish_larvae_thin_body',\n",
    "'fish_larvae_very_thin_body',\n",
    "'heteropod',\n",
    "'hydromedusae_aglaura',\n",
    "'hydromedusae_bell_and_tentacles',\n",
    "'hydromedusae_h15',\n",
    "'hydromedusae_haliscera',\n",
    "'hydromedusae_haliscera_small_sideview',\n",
    "'hydromedusae_liriope',\n",
    "'hydromedusae_narco_dark',\n",
    "'hydromedusae_narco_young',\n",
    "'hydromedusae_narcomedusae',\n",
    "'hydromedusae_other',\n",
    "'hydromedusae_partial_dark',\n",
    "'hydromedusae_shapeA',\n",
    "'hydromedusae_shapeA_sideview_small',\n",
    "'hydromedusae_shapeB',\n",
    "'hydromedusae_sideview_big',\n",
    "'hydromedusae_solmaris',\n",
    "'hydromedusae_solmundella',\n",
    "'hydromedusae_typeD',\n",
    "'hydromedusae_typeD_bell_and_tentacles',\n",
    "'hydromedusae_typeE',\n",
    "'hydromedusae_typeF',\n",
    "'invertebrate_larvae_other_A',\n",
    "'invertebrate_larvae_other_B',\n",
    "'jellies_tentacles',\n",
    "'polychaete',\n",
    "'protist_dark_center',\n",
    "'protist_fuzzy_olive',\n",
    "'protist_noctiluca',\n",
    "'protist_other',\n",
    "'protist_star',\n",
    "'pteropod_butterfly',\n",
    "'pteropod_theco_dev_seq',\n",
    "'pteropod_triangle',\n",
    "'radiolarian_chain',\n",
    "'radiolarian_colony',\n",
    "'shrimp-like_other',\n",
    "'shrimp_caridean',\n",
    "'shrimp_sergestidae',\n",
    "'shrimp_zoea',\n",
    "'siphonophore_calycophoran_abylidae',\n",
    "'siphonophore_calycophoran_rocketship_adult',\n",
    "'siphonophore_calycophoran_rocketship_young',\n",
    "'siphonophore_calycophoran_sphaeronectes',\n",
    "'siphonophore_calycophoran_sphaeronectes_stem',\n",
    "'siphonophore_calycophoran_sphaeronectes_young',\n",
    "'siphonophore_other_parts',\n",
    "'siphonophore_partial',\n",
    "'siphonophore_physonect',\n",
    "'siphonophore_physonect_young',\n",
    "'stomatopod',\n",
    "'tornaria_acorn_worm_larvae',\n",
    "'trichodesmium_bowtie',\n",
    "'trichodesmium_multiple',\n",
    "'trichodesmium_puff',\n",
    "'trichodesmium_tuft',\n",
    "'trochophore_larvae',\n",
    "'tunicate_doliolid',\n",
    "'tunicate_doliolid_nurse',\n",
    "'tunicate_partial',\n",
    "'tunicate_salp',\n",
    "'tunicate_salp_chains',\n",
    "'unknown_blobs_and_smudges',\n",
    "'unknown_sticks',\n",
    "'unknown_unclassified']\n",
    "\n",
    "classlist_mapping = {}\n",
    "\n",
    "for item in classlist:\n",
    "    new_name = input(f\"Enter new name for {item}: \")\n",
    "    classlist_mapping[item] = new_name\n",
    "\n",
    "print(classlist_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ImageProcessing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
